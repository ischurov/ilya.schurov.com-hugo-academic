---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Learning complexity of many-body quantum sign structures through the lens of Boolean Fourier analysis
subtitle: ''
summary: ''
authors:
- Ilya Schurov
- Anna Kravchenko
- Mikhail I. Katsnelson
- Andrey A. Bagrov
- Tom Westerhout
tags: ['physics', 'neural networks', 'complexity']
categories: []
date: '2025-08-13'
lastmod: 2025-08-13T14:41:07+02:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
# publishDate: '2022-03-28T15:48:07.210035Z'
publication_types:
- '2'
abstract: 'We study sign structures of the ground states of spin-1/2 magnetic systems using the methods of Boolean Fourier analysis. Previously it was shown that the sign structures of frustrated systems are of complex nature: specifically, neural networks of popular architectures lack the generalization ability necessary to effectively reconstruct sign structures in supervised learning settings. This is believed to be an obstacle for applications of neural quantum states to frustrated systems. In the present work, we develop an alternative language for the analysis of sign structures based on representing them as polynomial functions defined on the Boolean hypercube - an approach called Boolean Fourier analysis. We discuss the relations between the properties of the Boolean Fourier series and the learning complexity of sign structures, and demonstrate that such polynomials can potentially serve as variational ansätze for the complex sign structures that dramatically outperform neural networks in terms of generalization ability. While ansätze of this type cannot yet be directly used in the context of variational optimization, they indicate that the complexity of sign structures is not an insurmountable curse, and can potentially be learned with better designed NQS architectures. Finally, we show how augmenting data with Boolean functions can aid sign prediction by neural networks.'
publication: 'arXiv:2508.09870'
doi: 10.48550/arXiv.2508.09870
links:
- name: arXiv
  url: https://arxiv.org/abs/2508.09870
---
